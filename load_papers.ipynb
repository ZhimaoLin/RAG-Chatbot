{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Papers to Pinecone Vector Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages\n",
    "\n",
    "If you are using MacOS, please use `pip3`.\n",
    "\n",
    "`-qU` means `quiet` and `Upgrade`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    langchain==0.0.276 \\\n",
    "    openai==0.27.10 \\\n",
    "    tiktoken==0.4.0 \\\n",
    "    pinecone-client==2.2.2 \\\n",
    "    wikipedia==1.4.0 \\\n",
    "    pypdf==3.15.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings   \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "import pinecone\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "from config import OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_ENVIRONMENT, PINECONE_INDEX_NAME, EMBEDDING_MODEL, SPLITTER_CHUNK_SIZE, SPLITTER_CHUNK_OVERLAP, UPLOAD_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variable\n",
    "\n",
    "- `PAPER_LIST`: Store file paths of upload papers into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_LIST = [\"data/paper1.pdf\", \"data/paper2.pdf\", \"data/paper3.pdf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_match(result):\n",
    "    for match in result['matches']:\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Score: {match['score']:.2f} \\t Source: {match['metadata']['source']} \\t Page: {int(match['metadata']['page'])}\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"{match['metadata']['text']}\")\n",
    "        print(\"=\"*60)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Embedding\n",
    "\n",
    "Here `text-embedding-ada-002` embedding is used by default. Please refer to [OpenAI embedding document](https://platform.openai.com/docs/guides/embeddings/embedding-models) for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "OpenAI initialization: OK\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_model = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY, \n",
    "    model=EMBEDDING_MODEL\n",
    ")\n",
    "\n",
    "print(\"=\"*30)\n",
    "print(\"OpenAI initialization: OK\")\n",
    "print(\"=\"*30)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Pinecone\n",
    "\n",
    "If the index does not exist in your Pinecone, it will automatically create a new one. \n",
    "\n",
    "- `metric='cosine'`: This is often used to find similarities between different documents. The advantage is that the scores are normalized to [-1,1] range. You can choose other options listed [here](https://docs.pinecone.io/docs/indexes#distance-metrics).\n",
    "- `dimension=1536`: The OpenAI `text-embedding-ada-002` embedding has a dimension of 1536\n",
    "- There is a limitation for the free plan for Pinecone. Please refer to the [starter plan](https://docs.pinecone.io/docs/indexes#starter-plan) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Pinecone initialization: OK\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.01366,\n",
      " 'namespaces': {'': {'vector_count': 1366}},\n",
      " 'total_vector_count': 1366}\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRONMENT\n",
    ")\n",
    "\n",
    "if PINECONE_INDEX_NAME not in pinecone.list_indexes():\n",
    "    # we create a new index if it doesn't exist\n",
    "    pinecone.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        metric='cosine',\n",
    "        dimension=1536  # 1536 dim of text-embedding-ada-002\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    time.sleep(1)\n",
    "\n",
    "pinecone_index = pinecone.Index(PINECONE_INDEX_NAME)\n",
    "pinecone_stats = pinecone_index.describe_index_stats()\n",
    "print(\"=\"*30)\n",
    "print(\"Pinecone initialization: OK\")\n",
    "print(pinecone_stats)\n",
    "print(\"=\"*30)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload PDF Files\n",
    "\n",
    "### Load PDFs\n",
    "\n",
    "`PyPDF` is used to load the PDFs and [Tiktoken Splitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/split_by_token#tiktoken) is used to split the document by tokens. This tokenizer is created by OpenAI, so it is more accurate for OpenAI models. \n",
    "\n",
    "- `chunk_size=100`: Combine 100 tokens into a chunk in order to give the model more context for each source it retrieves from the vector store.\n",
    "- `chunk_overlap=25`: Considering most papers have two columns, so there will be more cut-off and broken texts. 1/4 of the chunk size is used for overlapping to mitigate the effect of cut-off and broken texts.\n",
    "\n",
    "### Embedding\n",
    "\n",
    "Then, each chunk is embedded to a vector with a dimension of 1536 using the OpenAI embedding model mentioned above. However, in order to upload the vectors to Pinecone, the vectors has to be in [this format](https://docs.pinecone.io/docs/python-client#indexupsert). \n",
    "\n",
    "```\n",
    "upsert_response = index.upsert(\n",
    "   vectors=[\n",
    "       {'id': \"vec1\", \"values\":[0.1, 0.2, 0.3, 0.4], \"metadata\": {'genre': 'drama'}},\n",
    "       {'id': \"vec2\", \"values\":[0.2, 0.3, 0.4, 0.5], \"metadata\": {'genre': 'action'}},\n",
    "   ],\n",
    "   namespace='example-namespace'\n",
    ")\n",
    "```\n",
    "\n",
    "- Here, `str(uuid.uuid4())` is used as `id` instead of a string of an incrementing integer since the number of vectors is huge. Approximately, 300 vectors per PDF. \n",
    "- The original text, file name, and the page number of the text are stored as metadata.\n",
    "  - For demo purpose, only this information is stored. More information such as paper title, publish date, and authors etc. can be stored as metadata.\n",
    "\n",
    "### Batch Upload\n",
    "\n",
    "Due to efficiency, vectors are uploaded to Pinecone in batches. By default, the batch size is `32`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in PAPER_LIST:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load_and_split()\n",
    "    print(f\"Processing [{file_path}]\")\n",
    "    print(f\"Pages shape: {len(pages)}\")\n",
    "\n",
    "    text_splitter = TokenTextSplitter(\n",
    "        chunk_size=SPLITTER_CHUNK_SIZE, \n",
    "        chunk_overlap=SPLITTER_CHUNK_OVERLAP\n",
    "    )\n",
    "\n",
    "    source = pages[0].metadata[\"source\"]\n",
    "\n",
    "    total_sentences = []\n",
    "    page_number_list = []\n",
    "    for idx, page in enumerate(pages):\n",
    "        page_num = page.metadata[\"page\"] + 1\n",
    "        sentences = text_splitter.split_text(page.page_content)\n",
    "        total_sentences += sentences\n",
    "        page_number_list += [page_num] * len(sentences)\n",
    "\n",
    "    # Due to OpenAPI rate limitation, I have to embed multiple chunks at the same time\n",
    "    paper_embedding = embedding_model.embed_documents(total_sentences)\n",
    "\n",
    "    # Reformat the vectors\n",
    "    to_upsert = []\n",
    "    for i, sentence_vector in enumerate(paper_embedding):\n",
    "        to_upsert.append({\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"values\": sentence_vector,\n",
    "            \"metadata\": {\n",
    "                            \"text\": total_sentences[i],\n",
    "                            \"source\": source,\n",
    "                            \"page\": page_number_list[i]\n",
    "                        }\n",
    "        })\n",
    "\n",
    "    # Upload the vectors in baches\n",
    "    batch_size = UPLOAD_BATCH_SIZE\n",
    "    n = len(to_upsert)\n",
    "    print(f\"Total number: {n}\")\n",
    "\n",
    "    for i in range(0, n, batch_size):\n",
    "        if i + batch_size <= n:\n",
    "            batch = to_upsert[i: i+batch_size]     \n",
    "        else:\n",
    "            batch = to_upsert[i:]\n",
    "\n",
    "        pinecone_index.upsert(vectors=batch)\n",
    "        print(f\"Uploaded batch [{i} : {min(n, i+batch_size)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Automatically test the upload results using some queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Test 1: Why the dot products get large in transformer?\n",
      "==============================\n",
      "============================================================\n",
      "Score: 0.80 \t Source: data/test.pdf \t Page: 4\n",
      "============================================================\n",
      " values of\n",
      "dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\n",
      "extremely small gradients4. To counteract this effect, we scale the dot products by1√dk.\n",
      "3.2.2 Multi-Head Attention\n",
      "Instead of performing a single attention function with dmodel-dimensional keys, values and queries,\n",
      "we found it beneficial to linearly project the queries, keys and values htimes with different, learned\n",
      "linear projections to\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Score: 0.79 \t Source: data/test.pdf \t Page: 4\n",
      "============================================================\n",
      "\n",
      "we found it beneficial to linearly project the queries, keys and values htimes with different, learned\n",
      "linear projections to dk,dkanddvdimensions, respectively. On each of these projected versions of\n",
      "queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n",
      "4To illustrate why the dot products get large, assume that the components of qandkare independent random\n",
      "variables with mean 0and variance 1. Then their dot\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Score: 0.79 \t Source: data/test.pdf \t Page: 4\n",
      "============================================================\n",
      "Scaled Dot-Product Attention\n",
      " Multi-Head Attention\n",
      "Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\n",
      "attention layers running in parallel.\n",
      "of the values, where the weight assigned to each value is computed by a compatibility function of the\n",
      "query with the corresponding key.\n",
      "3.2.1 Scaled Dot-Product Attention\n",
      "We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2).\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Why the dot products get large in transformer?\"\n",
    "print(\"=\"*30)\n",
    "print(f\"Test 1: {query}\")\n",
    "print(\"=\"*30)\n",
    "query_embedding = embedding_model.embed_documents([query])\n",
    "res = pinecone_index.query(query_embedding, top_k=3, include_metadata=True)\n",
    "print_match(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Test 2: How to treat patient with ACHD?\n",
      "==============================\n",
      "============================================================\n",
      "Score: 0.86 \t Source: data/paper1.pdf \t Page: 6\n",
      "============================================================\n",
      "oided in patients with AR.RECOMMENDATION\n",
      "15. We recommend early referral for assessment of HTx\n",
      "in patients with ACHD with progressive cardiacsymptoms despite optimal medical, surgical, and\n",
      "interventional therapies (Strong Recommendation,\n",
      "Very Low-Quality Evidence).340 Canadian Journal of Cardiology\n",
      "Volume 36 2020\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Score: 0.85 \t Source: data/paper1.pdf \t Page: 6\n",
      "============================================================\n",
      ". ACHD patients should be referred early\n",
      "and followed by transplant and ACHD teams to determine\n",
      "optimal timing for transplant listing. HTx should be\n",
      "considered as a potential management strategy in ACHDpatients even when some surgical options might be\n",
      "available.\n",
      "Anatomic substrate, including systemic right vs left\n",
      "ventricle and single vs biventricular heart has been associatedwith pretransplantation outcomes.\n",
      "59,65Brain natriuretic pep\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Score: 0.85 \t Source: data/paper1.pdf \t Page: 7\n",
      "============================================================\n",
      " trans-plantation (Strong Recommendation, Low-Quality\n",
      "Evidence).\n",
      "Values and preferences. Factors unique to patients\n",
      "with ACHD must be considered during HTx assessment.\n",
      "RECOMMENDATION\n",
      "17. We recommend particular attention be paid to the\n",
      "effect of older donor age and/or longer ischemic timeon survival outcomes when considering a donor organ\n",
      "for a patient with ACHD (Strong Recommendation,\n",
      "Moderate-Quality Evidence).\n",
      "Values and preferences\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How to treat patient with ACHD?\"\n",
    "print(\"=\"*30)\n",
    "print(f\"Test 2: {query}\")\n",
    "print(\"=\"*30)\n",
    "query_embedding = embedding_model.embed_documents([query])\n",
    "res = pinecone_index.query(query_embedding, top_k=3, include_metadata=True)\n",
    "print_match(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Test 3: How to diagnose Resistant Hypertension?\n",
      "==============================\n",
      "============================================================\n",
      "Score: 0.91 \t Source: data/paper3.pdf \t Page: 4\n",
      "============================================================\n",
      "R\n",
      "C\n",
      "Conﬁrm diagnosis of true resistant hypertension\n",
      "Figure 1. Diagnostic algorithm for a patient with suspected resistant hypertension. ABPM, ambulatory blood pressure monitoring; BP, blood\n",
      "pressure; HT, hypertension. *Three or more drugs, at optimally tolerated dosages, and preferably including a diuretic.yHome BP monitoring can be\n",
      "performed if ABPM is not accessible.628 Canadian Journal of Cardiology\n",
      "Volume 36 2020\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Score: 0.88 \t Source: data/paper3.pdf \t Page: 3\n",
      "============================================================\n",
      "Hypertension Canada ’s 2020 Guidelines on\n",
      "Resistant Hypertension\n",
      "Epidemiology of RHT\n",
      "RHT is de ﬁned as having a BP above target with use of at\n",
      "least 3 medications, at optimal doses, including a diuretic.True RHT is diagnosed when causes of pseudoresistance and\n",
      "secondary causes are further excluded. Causes of pseudore-\n",
      "sistance, also termed “apparent treatment-resistant hyperten-\n",
      "s\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Score: 0.87 \t Source: data/paper3.pdf \t Page: 9\n",
      "============================================================\n",
      "Carey RM, Calhoun DA, Bakris GL, et al. Resistant hypertension:\n",
      "detection, evaluation, and management: a scienti ﬁc statement from the\n",
      "American Heart Association. Hypertension 2018;72:e53-90 .\n",
      "16.Bangalore S, Fayyad R, Laskey R, et al. Prevalence, predictors, and\n",
      "outcomes in treatment-resistant hypertension in patients with coronarydisease. Am J\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How to diagnose Resistant Hypertension?\"\n",
    "print(\"=\"*30)\n",
    "print(f\"Test 3: {query}\")\n",
    "print(\"=\"*30)\n",
    "query_embedding = embedding_model.embed_documents([query])\n",
    "res = pinecone_index.query(query_embedding, top_k=3, include_metadata=True)\n",
    "print_match(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Test 4: How to reduce the cardiorenal risk?\n",
      "==============================\n",
      "============================================================\n",
      "Score: 0.88 \t Source: data/paper2.pdf \t Page: 15\n",
      "============================================================\n",
      "ca.2022.04.029 .Mancini et al. 1167\n",
      "CCS Guideline for Cardiorenal Risk Reduction\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Score: 0.88 \t Source: data/paper2.pdf \t Page: 9\n",
      "============================================================\n",
      "and hospitalization for HF (Strong recommendation,Moderate-Quality Evidence).Mancini et al. 1161\n",
      "CCS Guideline for Cardiorenal Risk Reduction\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Score: 0.87 \t Source: data/paper2.pdf \t Page: 13\n",
      "============================================================\n",
      " 1165\n",
      "CCS Guideline for Cardiorenal Risk Reduction\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How to reduce the cardiorenal risk?\"\n",
    "print(\"=\"*30)\n",
    "print(f\"Test 4: {query}\")\n",
    "print(\"=\"*30)\n",
    "query_embedding = embedding_model.embed_documents([query])\n",
    "res = pinecone_index.query(query_embedding, top_k=3, include_metadata=True)\n",
    "print_match(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
