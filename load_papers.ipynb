{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \\\n",
    "#   langchain==0.0.276 \\\n",
    "#   openai==0.27.10 \\\n",
    "#   tiktoken==0.4.0 \\\n",
    "#   sentence-transformers==2.2.2 \\\n",
    "#   spacy==3.6.1 \\\n",
    "#   nltk==3.8.1 \\\n",
    "#   pinecone-client==2.2.2 \\\n",
    "#   pypdf==3.15.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tom\\AppData\\Roaming\\Python\\Python39\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings   \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, NLTKTextSplitter, TokenTextSplitter, SpacyTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "\n",
    "import pinecone\n",
    "import itertools\n",
    "import time\n",
    "import uuid\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_ENVIRONMENT, PINECONE_INDEX_NAME, EMBEDDING_MODEL, SPLITTER_CHUNK_SIZE, SPLITTER_CHUNK_OVERLAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY, \n",
    "    model=EMBEDDING_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRONMENT\n",
    ")\n",
    "\n",
    "if PINECONE_INDEX_NAME not in pinecone.list_indexes():\n",
    "    # we create a new index if it doesn't exist\n",
    "    pinecone.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        metric='cosine',\n",
    "        dimension=1536  # 1536 dim of text-embedding-ada-002\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    time.sleep(1)\n",
    "\n",
    "pinecone_index = pinecone.Index(PINECONE_INDEX_NAME)\n",
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages shape: 16\n",
      "Page [1]\n",
      "Sentences shape: 29\n",
      "Page [2]\n",
      "Sentences shape: 33\n",
      "Page [3]\n",
      "Sentences shape: 5\n",
      "Page [4]\n",
      "Sentences shape: 18\n",
      "Page [5]\n",
      "Sentences shape: 23\n",
      "Page [6]\n",
      "Sentences shape: 32\n",
      "Page [7]\n",
      "Sentences shape: 34\n",
      "Page [8]\n",
      "Sentences shape: 32\n",
      "Page [9]\n",
      "Sentences shape: 37\n",
      "Page [10]\n",
      "Sentences shape: 34\n",
      "Page [11]\n",
      "Sentences shape: 35\n",
      "Page [12]\n",
      "Sentences shape: 41\n",
      "Page [13]\n",
      "Sentences shape: 40\n",
      "Page [14]\n",
      "Sentences shape: 11\n",
      "Page [15]\n",
      "Sentences shape: 13\n",
      "Page [16]\n",
      "Sentences shape: 13\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"data/test.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "print(f\"Pages shape: {len(pages)}\")\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=SPLITTER_CHUNK_SIZE, chunk_overlap=SPLITTER_CHUNK_OVERLAP)\n",
    "\n",
    "total_sentences = []\n",
    "for idx, page in enumerate(pages):\n",
    "    print(f\"Page [{idx+1}]\")\n",
    "    sentences = text_splitter.split_text(page.page_content)\n",
    "    print(f\"Sentences shape: {len(sentences)}\")\n",
    "    total_sentences += sentences\n",
    "\n",
    "paper_embedding = embedding_model.embed_documents(total_sentences)\n",
    "\n",
    "to_upsert = []\n",
    "for i, sentence_vector in enumerate(paper_embedding):\n",
    "    to_upsert.append({\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"values\": sentence_vector,\n",
    "        \"metadata\": {'text': total_sentences[i]}\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number: 430\n",
      "Uploaded batch [0 : 32]\n",
      "Uploaded batch [32 : 64]\n",
      "Uploaded batch [64 : 96]\n",
      "Uploaded batch [96 : 128]\n",
      "Uploaded batch [128 : 160]\n",
      "Uploaded batch [160 : 192]\n",
      "Uploaded batch [192 : 224]\n",
      "Uploaded batch [224 : 256]\n",
      "Uploaded batch [256 : 288]\n",
      "Uploaded batch [288 : 320]\n",
      "Uploaded batch [320 : 352]\n",
      "Uploaded batch [352 : 384]\n",
      "Uploaded batch [384 : 416]\n",
      "Uploaded batch [416 : 430]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n = len(to_upsert)\n",
    "print(f\"Total number: {n}\")\n",
    "\n",
    "for i in range(0, n, batch_size):\n",
    "    if i + batch_size <= n:\n",
    "        batch = to_upsert[i: i+batch_size]     \n",
    "    else:\n",
    "        batch = to_upsert[i:]\n",
    "\n",
    "    pinecone_index.upsert(vectors=batch)\n",
    "    print(f\"Uploaded batch [{i} : {min(n, i+batch_size)}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83:  values of\n",
      "dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\n",
      "extremely small gradients4.\n",
      "0.81:  values we then perform the attention function in parallel, yielding dv-dimensional\n",
      "4To illustrate why the dot products get large, assume that the components\n",
      "0.79:  small gradients4. To counteract this effect, we scale the dot products by1âˆšdk.\n",
      "3.2.2 Multi-Head\n",
      "0.79: , additive attention outperforms\n",
      "dot product attention without scaling for larger values of dk[3]. We suspect that for large values of\n",
      "dk,\n",
      "0.79: 1 Scaled Dot-Product Attention\n",
      "We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = [\"Why the dot products get large\"]\n",
    "query_embedding = embedding_model.embed_documents(query)\n",
    "res = pinecone_index.query(query_embedding, top_k=5, include_metadata=True)\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82: les, at a fraction of the training cost of any of\n",
      "the competitive models.\n",
      "On the WMT 2014 English-to-French translation task\n",
      "0.81:  the significantly larger WMT\n",
      "2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\n",
      "vocabulary [\n",
      "0.80: MT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU\n",
      "0.80: Parser Training WSJ 23 F1\n",
      "Vinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88\n",
      "0.80: .\n",
      "For translation tasks, the Transformer can be trained significantly faster than architectures based\n",
      "on recurrent or convolutional layers. On both WMT\n"
     ]
    }
   ],
   "source": [
    "query = [\"How is the training on the WMT 2014 dataset?\"]\n",
    "query_embedding = embedding_model.embed_documents(query)\n",
    "res = pinecone_index.query(query_embedding, top_k=5, include_metadata=True)\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
