{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \\\n",
    "#   langchain==0.0.276 \\\n",
    "#   openai==0.27.10 \\\n",
    "#   tiktoken==0.4.0 \\\n",
    "#   sentence-transformers==2.2.2 \\\n",
    "#   spacy==3.6.1 \\\n",
    "#   nltk==3.8.1 \\\n",
    "#   pinecone-client==2.2.2 \\\n",
    "#   wikipedia==1.4.0 \\\n",
    "#   pypdf==3.15.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings   \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, NLTKTextSplitter, TokenTextSplitter, SpacyTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "\n",
    "import pinecone\n",
    "import itertools\n",
    "import time\n",
    "import uuid\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from config import OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_ENVIRONMENT, PINECONE_INDEX_NAME, EMBEDDING_MODEL, SPLITTER_CHUNK_SIZE, SPLITTER_CHUNK_OVERLAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY, \n",
    "    model=EMBEDDING_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.04929,\n",
       " 'namespaces': {'': {'vector_count': 4929}},\n",
       " 'total_vector_count': 4929}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRONMENT\n",
    ")\n",
    "\n",
    "if PINECONE_INDEX_NAME not in pinecone.list_indexes():\n",
    "    # we create a new index if it doesn't exist\n",
    "    pinecone.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        metric='cosine',\n",
    "        dimension=1536  # 1536 dim of text-embedding-ada-002\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    time.sleep(1)\n",
    "\n",
    "pinecone_index = pinecone.Index(PINECONE_INDEX_NAME)\n",
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages shape: 38\n",
      "Page [1]\n",
      "Sentences shape: 7\n",
      "Page [2]\n",
      "Sentences shape: 16\n",
      "Page [3]\n",
      "Sentences shape: 62\n",
      "Page [4]\n",
      "Sentences shape: 34\n",
      "Page [5]\n",
      "Sentences shape: 26\n",
      "Page [6]\n",
      "Sentences shape: 26\n",
      "Page [7]\n",
      "Sentences shape: 21\n",
      "Page [8]\n",
      "Sentences shape: 7\n",
      "Page [9]\n",
      "Sentences shape: 9\n",
      "Page [10]\n",
      "Sentences shape: 23\n",
      "Page [11]\n",
      "Sentences shape: 29\n",
      "Page [12]\n",
      "Sentences shape: 35\n",
      "Page [13]\n",
      "Sentences shape: 26\n",
      "Page [14]\n",
      "Sentences shape: 17\n",
      "Page [15]\n",
      "Sentences shape: 18\n",
      "Page [16]\n",
      "Sentences shape: 11\n",
      "Page [17]\n",
      "Sentences shape: 10\n",
      "Page [18]\n",
      "Sentences shape: 26\n",
      "Page [19]\n",
      "Sentences shape: 18\n",
      "Page [20]\n",
      "Sentences shape: 34\n",
      "Page [21]\n",
      "Sentences shape: 3\n",
      "Page [22]\n",
      "Sentences shape: 10\n",
      "Page [23]\n",
      "Sentences shape: 21\n",
      "Page [24]\n",
      "Sentences shape: 22\n",
      "Page [25]\n",
      "Sentences shape: 21\n",
      "Page [26]\n",
      "Sentences shape: 28\n",
      "Page [27]\n",
      "Sentences shape: 36\n",
      "Page [28]\n",
      "Sentences shape: 8\n",
      "Page [29]\n",
      "Sentences shape: 21\n",
      "Page [30]\n",
      "Sentences shape: 22\n",
      "Page [31]\n",
      "Sentences shape: 15\n",
      "Page [32]\n",
      "Sentences shape: 21\n",
      "Page [33]\n",
      "Sentences shape: 21\n",
      "Page [34]\n",
      "Sentences shape: 20\n",
      "Page [35]\n",
      "Sentences shape: 17\n",
      "Page [36]\n",
      "Sentences shape: 19\n",
      "Page [37]\n",
      "Sentences shape: 45\n",
      "Page [38]\n",
      "Sentences shape: 38\n"
     ]
    }
   ],
   "source": [
    "paper_list = [\"data/paper1.pdf\", \"data/paper2.pdf\", \"data/paper3.pdf\", \"data/test.pdf\", \"data/mypaper.pdf\"]\n",
    "\n",
    "loader = PyPDFLoader(\"data/mypaper.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "print(f\"Pages shape: {len(pages)}\")\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=SPLITTER_CHUNK_SIZE, chunk_overlap=SPLITTER_CHUNK_OVERLAP)\n",
    "\n",
    "source = pages[0].metadata[\"source\"]\n",
    "\n",
    "total_sentences = []\n",
    "page_number_list = []\n",
    "for idx, page in enumerate(pages):\n",
    "    page_num = page.metadata[\"page\"] + 1\n",
    "    print(f\"Page [{idx+1}]\")\n",
    "    sentences = text_splitter.split_text(page.page_content)\n",
    "    print(f\"Sentences shape: {len(sentences)}\")\n",
    "    total_sentences += sentences\n",
    "    page_number_list += [page_num] * len(sentences)\n",
    "\n",
    "# Due to OpenAPI rate limitation, I have to embed multiple chunks at the same time\n",
    "paper_embedding = embedding_model.embed_documents(total_sentences)\n",
    "\n",
    "to_upsert = []\n",
    "for i, sentence_vector in enumerate(paper_embedding):\n",
    "    to_upsert.append({\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"values\": sentence_vector,\n",
    "        \"metadata\": {\n",
    "                        \"text\": total_sentences[i],\n",
    "                        \"source\": source,\n",
    "                        \"page\": page_number_list[i]\n",
    "                    }\n",
    "    })\n",
    "\n",
    "# print(to_upsert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number: 843\n",
      "Uploaded batch [0 : 32]\n",
      "Uploaded batch [32 : 64]\n",
      "Uploaded batch [64 : 96]\n",
      "Uploaded batch [96 : 128]\n",
      "Uploaded batch [128 : 160]\n",
      "Uploaded batch [160 : 192]\n",
      "Uploaded batch [192 : 224]\n",
      "Uploaded batch [224 : 256]\n",
      "Uploaded batch [256 : 288]\n",
      "Uploaded batch [288 : 320]\n",
      "Uploaded batch [320 : 352]\n",
      "Uploaded batch [352 : 384]\n",
      "Uploaded batch [384 : 416]\n",
      "Uploaded batch [416 : 448]\n",
      "Uploaded batch [448 : 480]\n",
      "Uploaded batch [480 : 512]\n",
      "Uploaded batch [512 : 544]\n",
      "Uploaded batch [544 : 576]\n",
      "Uploaded batch [576 : 608]\n",
      "Uploaded batch [608 : 640]\n",
      "Uploaded batch [640 : 672]\n",
      "Uploaded batch [672 : 704]\n",
      "Uploaded batch [704 : 736]\n",
      "Uploaded batch [736 : 768]\n",
      "Uploaded batch [768 : 800]\n",
      "Uploaded batch [800 : 832]\n",
      "Uploaded batch [832 : 843]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n = len(to_upsert)\n",
    "print(f\"Total number: {n}\")\n",
    "\n",
    "for i in range(0, n, batch_size):\n",
    "    if i + batch_size <= n:\n",
    "        batch = to_upsert[i: i+batch_size]     \n",
    "    else:\n",
    "        batch = to_upsert[i:]\n",
    "\n",
    "    pinecone_index.upsert(vectors=batch)\n",
    "    print(f\"Uploaded batch [{i} : {min(n, i+batch_size)}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\"How to treat patient with ACHD?\"]\n",
    "query_embedding = embedding_model.embed_documents(query)\n",
    "res = pinecone_index.query(query_embedding, top_k=3, include_metadata=True)\n",
    "for match in res['matches']:\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Score: {match['score']:.2f} \\t Source: {match['metadata']['source']}\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"{match['metadata']['text']}\")\n",
    "    print(\"=\"*30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\"Why the dot products get large?\"]\n",
    "query_embedding = embedding_model.embed_documents(query)\n",
    "res = pinecone_index.query(query_embedding, top_k=3, include_metadata=True)\n",
    "for match in res['matches']:\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Score: {match['score']:.2f} \\t Source: {match['metadata']['source']} \\t Page: {int(match['metadata']['page'])}\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"{match['metadata']['text']}\")\n",
    "    print(\"=\"*30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Score: 0.76 \t Source: data/mypaper.pdf \t Page: 3\n",
      "==============================\n",
      "2023-09-01 00:00:00\n",
      "==============================\n",
      "\n",
      "==============================\n",
      "Score: 0.76 \t Source: data/mypaper.pdf \t Page: 3\n",
      "==============================\n",
      " . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n",
      "4.1.3 Computer Vision . . .\n",
      "==============================\n",
      "\n",
      "==============================\n",
      "Score: 0.76 \t Source: data/mypaper.pdf \t Page: 3\n",
      "==============================\n",
      " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n",
      "2 Research\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = [\"Who is bill gates?\"]\n",
    "query_embedding = embedding_model.embed_documents(query)\n",
    "res = pinecone_index.query(query_embedding, top_k=3, include_metadata=True)\n",
    "for match in res['matches']:\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Score: {match['score']:.2f} \\t Source: {match['metadata']['source']} \\t Page: {int(match['metadata']['page'])}\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"{match['metadata']['text']}\")\n",
    "    print(\"=\"*30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
