{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \\\n",
    "#   langchain==0.0.276 \\\n",
    "#   openai==0.27.10 \\\n",
    "#   tiktoken==0.4.0 \\\n",
    "#   sentence-transformers==2.2.2 \\\n",
    "#   spacy==3.6.1 \\\n",
    "#   nltk==3.8.1 \\\n",
    "#   pinecone-client==2.2.2 \\\n",
    "#   pypdf==3.15.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings   \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, NLTKTextSplitter, TokenTextSplitter, SpacyTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "\n",
    "import pinecone\n",
    "import itertools\n",
    "import time\n",
    "import uuid\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from config import OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_ENVIRONMENT, PINECONE_INDEX_NAME, EMBEDDING_MODEL, SPLITTER_CHUNK_SIZE, SPLITTER_CHUNK_OVERLAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY, \n",
    "    model=EMBEDDING_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0043,\n",
       " 'namespaces': {'': {'vector_count': 430}},\n",
       " 'total_vector_count': 430}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRONMENT\n",
    ")\n",
    "\n",
    "if PINECONE_INDEX_NAME not in pinecone.list_indexes():\n",
    "    # we create a new index if it doesn't exist\n",
    "    pinecone.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        metric='cosine',\n",
    "        dimension=1536  # 1536 dim of text-embedding-ada-002\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    time.sleep(1)\n",
    "\n",
    "pinecone_index = pinecone.Index(PINECONE_INDEX_NAME)\n",
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages shape: 42\n",
      "Page [1]\n",
      "Sentences shape: 47\n",
      "Page [2]\n",
      "Sentences shape: 10\n",
      "Page [3]\n",
      "Sentences shape: 38\n",
      "Page [4]\n",
      "Sentences shape: 31\n",
      "Page [5]\n",
      "Sentences shape: 43\n",
      "Page [6]\n",
      "Sentences shape: 9\n",
      "Page [7]\n",
      "Sentences shape: 40\n",
      "Page [8]\n",
      "Sentences shape: 11\n",
      "Page [9]\n",
      "Sentences shape: 41\n",
      "Page [10]\n",
      "Sentences shape: 19\n",
      "Page [11]\n",
      "Sentences shape: 37\n",
      "Page [12]\n",
      "Sentences shape: 18\n",
      "Page [13]\n",
      "Sentences shape: 39\n",
      "Page [14]\n",
      "Sentences shape: 19\n",
      "Page [15]\n",
      "Sentences shape: 38\n",
      "Page [16]\n",
      "Sentences shape: 9\n",
      "Page [17]\n",
      "Sentences shape: 45\n",
      "Page [18]\n",
      "Sentences shape: 10\n",
      "Page [19]\n",
      "Sentences shape: 40\n",
      "Page [20]\n",
      "Sentences shape: 15\n",
      "Page [21]\n",
      "Sentences shape: 41\n",
      "Page [22]\n",
      "Sentences shape: 14\n",
      "Page [23]\n",
      "Sentences shape: 39\n",
      "Page [24]\n",
      "Sentences shape: 13\n",
      "Page [25]\n",
      "Sentences shape: 37\n",
      "Page [26]\n",
      "Sentences shape: 37\n",
      "Page [27]\n",
      "Sentences shape: 12\n",
      "Page [28]\n",
      "Sentences shape: 38\n",
      "Page [29]\n",
      "Sentences shape: 42\n",
      "Page [30]\n",
      "Sentences shape: 11\n",
      "Page [31]\n",
      "Sentences shape: 46\n",
      "Page [32]\n",
      "Sentences shape: 26\n",
      "Page [33]\n",
      "Sentences shape: 50\n",
      "Page [34]\n",
      "Sentences shape: 35\n",
      "Page [35]\n",
      "Sentences shape: 47\n",
      "Page [36]\n",
      "Sentences shape: 37\n",
      "Page [37]\n",
      "Sentences shape: 49\n",
      "Page [38]\n",
      "Sentences shape: 37\n",
      "Page [39]\n",
      "Sentences shape: 48\n",
      "Page [40]\n",
      "Sentences shape: 35\n",
      "Page [41]\n",
      "Sentences shape: 49\n",
      "Page [42]\n",
      "Sentences shape: 5\n"
     ]
    }
   ],
   "source": [
    "paper_list = [\"data/paper1.pdf\", \"data/paper2.pdf\", \"data/paper3.pdf\", \"data/test.pdf\"]\n",
    "\n",
    "loader = PyPDFLoader(\"data/paper1.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "print(f\"Pages shape: {len(pages)}\")\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=SPLITTER_CHUNK_SIZE, chunk_overlap=SPLITTER_CHUNK_OVERLAP)\n",
    "\n",
    "total_sentences = []\n",
    "for idx, page in enumerate(pages):\n",
    "    print(f\"Page [{idx+1}]\")\n",
    "    sentences = text_splitter.split_text(page.page_content)\n",
    "    print(f\"Sentences shape: {len(sentences)}\")\n",
    "\n",
    "    total_sentences += sentences\n",
    "\n",
    "paper_embedding = embedding_model.embed_documents(total_sentences)\n",
    "\n",
    "to_upsert = []\n",
    "for i, sentence_vector in enumerate(paper_embedding):\n",
    "    to_upsert.append({\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"values\": sentence_vector,\n",
    "        \"metadata\": {'text': total_sentences[i]}\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number: 1307\n",
      "Uploaded batch [0 : 32]\n",
      "Uploaded batch [32 : 64]\n",
      "Uploaded batch [64 : 96]\n",
      "Uploaded batch [96 : 128]\n",
      "Uploaded batch [128 : 160]\n",
      "Uploaded batch [160 : 192]\n",
      "Uploaded batch [192 : 224]\n",
      "Uploaded batch [224 : 256]\n",
      "Uploaded batch [256 : 288]\n",
      "Uploaded batch [288 : 320]\n",
      "Uploaded batch [320 : 352]\n",
      "Uploaded batch [352 : 384]\n",
      "Uploaded batch [384 : 416]\n",
      "Uploaded batch [416 : 448]\n",
      "Uploaded batch [448 : 480]\n",
      "Uploaded batch [480 : 512]\n",
      "Uploaded batch [512 : 544]\n",
      "Uploaded batch [544 : 576]\n",
      "Uploaded batch [576 : 608]\n",
      "Uploaded batch [608 : 640]\n",
      "Uploaded batch [640 : 672]\n",
      "Uploaded batch [672 : 704]\n",
      "Uploaded batch [704 : 736]\n",
      "Uploaded batch [736 : 768]\n",
      "Uploaded batch [768 : 800]\n",
      "Uploaded batch [800 : 832]\n",
      "Uploaded batch [832 : 864]\n",
      "Uploaded batch [864 : 896]\n",
      "Uploaded batch [896 : 928]\n",
      "Uploaded batch [928 : 960]\n",
      "Uploaded batch [960 : 992]\n",
      "Uploaded batch [992 : 1024]\n",
      "Uploaded batch [1024 : 1056]\n",
      "Uploaded batch [1056 : 1088]\n",
      "Uploaded batch [1088 : 1120]\n",
      "Uploaded batch [1120 : 1152]\n",
      "Uploaded batch [1152 : 1184]\n",
      "Uploaded batch [1184 : 1216]\n",
      "Uploaded batch [1216 : 1248]\n",
      "Uploaded batch [1248 : 1280]\n",
      "Uploaded batch [1280 : 1307]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n = len(to_upsert)\n",
    "print(f\"Total number: {n}\")\n",
    "\n",
    "for i in range(0, n, batch_size):\n",
    "    if i + batch_size <= n:\n",
    "        batch = to_upsert[i: i+batch_size]     \n",
    "    else:\n",
    "        batch = to_upsert[i:]\n",
    "\n",
    "    pinecone_index.upsert(vectors=batch)\n",
    "    print(f\"Uploaded batch [{i} : {min(n, i+batch_size)}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87: with ACHD must be considered during HTx assessment.\n",
      "RECOMMENDATION\n",
      "17. We recommend particular attention be paid to the\n",
      "\n",
      "0.87: oided in patients with AR.RECOMMENDATION\n",
      "15. We recommend early referral for assessment of HTx\n",
      "in patients with ACHD\n",
      "0.87: ACHD patients.78It should be emphasized that observationalRECOMMENDATION\n",
      "16. We recommend patients with ACHD undergo eval-\n",
      "\n",
      "0.86: . ACHD patients should be referred early\n",
      "and followed by transplant and ACHD teams to determine\n",
      "optimal timing for transplant listing. HT\n",
      "0.85: \n",
      "symptoms when alternate management options are no longer\n",
      "effective and/or bene ﬁcial.\n",
      "Practical tip. ACHD patients\n"
     ]
    }
   ],
   "source": [
    "query = [\"How to treat patient with ACHD?\"]\n",
    "query_embedding = embedding_model.embed_documents(query)\n",
    "res = pinecone_index.query(query_embedding, top_k=5, include_metadata=True)\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82: les, at a fraction of the training cost of any of\n",
      "the competitive models.\n",
      "On the WMT 2014 English-to-French translation task\n",
      "0.81:  the significantly larger WMT\n",
      "2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\n",
      "vocabulary [\n",
      "0.80: MT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU\n",
      "0.80: Parser Training WSJ 23 F1\n",
      "Vinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88\n",
      "0.80: .\n",
      "For translation tasks, the Transformer can be trained significantly faster than architectures based\n",
      "on recurrent or convolutional layers. On both WMT\n"
     ]
    }
   ],
   "source": [
    "query = [\"How is the training on the WMT 2014 dataset?\"]\n",
    "query_embedding = embedding_model.embed_documents(query)\n",
    "res = pinecone_index.query(query_embedding, top_k=5, include_metadata=True)\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
